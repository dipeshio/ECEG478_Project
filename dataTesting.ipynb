{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath: vscode-notebook-cell:/c%3A/Users/User/Documents/Projects/ECEG478_Project/dataTesting.ipynb#W0sZmlsZQ%3D%3D\n",
    "%pip install seaborn\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T18:29:35.304754Z",
     "start_time": "2025-04-22T18:29:31.513632Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## loading in all of the important libraries\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b535f7b869d6fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:51:41.481706Z",
     "start_time": "2025-04-22T19:51:41.186440Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading in the two datasets (training and eval) and getting some metrics out of it\n",
    "df = pd.read_csv('FairFace/fairface_label_train.csv')\n",
    "df2 = pd.read_csv('FairFace/fairface_label_val.csv')\n",
    "# remove service_test column\n",
    "df = df.drop(columns=['service_test'])\n",
    "df2 = df2.drop(columns=['service_test'])\n",
    "\n",
    "## Combining the age bins of '60-69' and 'more than 70' into '60+' and relabeling the age bins\n",
    "df['age'] = df['age'].replace({'60-69': '60+', 'more than 70': '60+'})\n",
    "df2['age'] = df2['age'].replace({'60-69': '60+', 'more than 70': '60+'})\n",
    "\n",
    "# rename Latino_Hispanic to Latino\n",
    "df['race'] = df['race'].replace({'Latino_Hispanic': 'Latino'})\n",
    "df2['race'] = df2['race'].replace({'Latino_Hispanic': 'Latino'})\n",
    "\n",
    "# confirmation check\n",
    "# print(\"Value counts AFTER replacement, BEFORE filtering:\")\n",
    "# print(df['age'].value_counts())\n",
    "# print(f\"Total rows before filtering: {len(df)}\")\n",
    "\n",
    "df = df.drop_duplicates(subset=['file'], keep='first')\n",
    "df2 = df2.drop_duplicates(subset=['file'], keep='first')\n",
    "\n",
    "\n",
    "\n",
    "# encoding categorical labels\n",
    "age_bins = ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60+']\n",
    "\n",
    "# new column 'age' with the bins from above\n",
    "df = df[df['age'].isin(age_bins)]  # ensure only those bins are used\n",
    "df2 = df2[df2['age'].isin(age_bins)] \n",
    "\n",
    "\n",
    "# confirmation check post transform\n",
    "# print(\"\\nValue counts AFTER filtering:\")\n",
    "# print(df['age'].value_counts())\n",
    "# print(f\"Total rows after filtering: {len(df)}\")\n",
    "\n",
    "\n",
    "## these will be used to check what the encoding and decoding looks like\n",
    "age_encoder = LabelEncoder()\n",
    "df['age_label'] = age_encoder.fit_transform(df['age'])\n",
    "df2['age_label'] = age_encoder.fit_transform(df2['age'])\n",
    "\n",
    "\n",
    "gender_encoder = LabelEncoder()\n",
    "df['gender_label'] = gender_encoder.fit_transform(df['gender'])\n",
    "df2['gender_label'] = gender_encoder.fit_transform(df2['gender'])\n",
    "\n",
    "\n",
    "race_encoder = LabelEncoder()\n",
    "df['race_label'] = race_encoder.fit_transform(df['race'])\n",
    "df2['race_label'] = race_encoder.fit_transform(df2['race'])\n",
    "\n",
    "\n",
    "\n",
    "## generate random int in general\n",
    "def random_int(min_val, max_val):\n",
    "    # function that generates a random int between two input ranges\n",
    "    return np.random.randint(min_val, max_val + 1)\n",
    "\n",
    "def balance_by_multiple_attributes(df, attr_cols, n_per_group):\n",
    "    # function that balances the dataset by multiple attributes\n",
    "    \n",
    "    state_value = random_int(0, 140) ## for creating a random-random state\n",
    "    ## I saw that using a static random state value of 0 was causing the same random sample to be generated every time\n",
    "    \n",
    "    grouped = df.groupby(attr_cols)\n",
    "    print(\"Grouped DataFrame:\")\n",
    "    print(grouped.head())\n",
    "    balanced_df = grouped.apply(lambda x: x.sample(n=min(len(x), n_per_group), random_state=state_value))\n",
    "    balanced_df = balanced_df.reset_index(drop=True)\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1bf092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped DataFrame:\n",
      "              file    age  gender             race  age_label  gender_label  \\\n",
      "0        val/1.jpg    3-9    Male       East Asian          3             1   \n",
      "1        val/2.jpg  50-59  Female       East Asian          6             0   \n",
      "2        val/3.jpg  30-39    Male            White          4             1   \n",
      "3        val/4.jpg  20-29  Female           Latino          2             0   \n",
      "4        val/5.jpg  20-29    Male  Southeast Asian          2             1   \n",
      "...            ...    ...     ...              ...        ...           ...   \n",
      "6107  val/6108.jpg    0-2  Female   Middle Eastern          0             0   \n",
      "6262  val/6263.jpg    0-2  Female           Latino          0             0   \n",
      "6786  val/6787.jpg    0-2    Male           Latino          0             1   \n",
      "7372  val/7373.jpg    0-2    Male           Latino          0             1   \n",
      "9317  val/9318.jpg    0-2  Female            Black          0             0   \n",
      "\n",
      "      race_label  \n",
      "0              1  \n",
      "1              1  \n",
      "2              6  \n",
      "3              3  \n",
      "4              5  \n",
      "...          ...  \n",
      "6107           4  \n",
      "6262           3  \n",
      "6786           3  \n",
      "7372           3  \n",
      "9317           0  \n",
      "\n",
      "[557 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23232\\942877382.py:71: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_df = grouped.apply(lambda x: x.sample(n=min(len(x), n_per_group), random_state=state_value))\n"
     ]
    }
   ],
   "source": [
    "# TODO: I think creating a new set to sample from would be better than sampling from the original set\n",
    "## This is not being used right now, but this can be used as a reference for the future\n",
    "\n",
    "### These would be the larger sets (still smaller than the original set) that we can sample from\n",
    "# trainSet = balance_by_multiple_attributes(df, ['age_label', 'gender_label', 'race_label'], 500)\n",
    "# trainSet = trainSet.sample(frac=1, random_state=random_int(0,1500)).reset_index(drop=True)\n",
    "\n",
    "valSet = balance_by_multiple_attributes(df2, ['age_label', 'gender_label', 'race_label'], 100)\n",
    "# valSet = valSet.sample(frac=1, random_state=random_int(0,1500)).reset_index(drop=True)\n",
    "# print(valSet['file'].unique().shape)\n",
    "# print(valSet)\n",
    "\n",
    "# # ===================================================================================\n",
    "\n",
    "\n",
    "# trainingSet = balance_by_multiple_attributes(df, ['age_label', 'gender_label', 'race_label'], 250)\n",
    "# ## remove age and gender columns\n",
    "# trainingSet = trainingSet.drop(['age', 'gender','race'], axis=1)\n",
    "\n",
    "# ## remove indices that are in the training column so that they don't end up in the validation set\n",
    "# remaining = df[~df['file'].isin(trainingSet['file'])]\n",
    "\n",
    "# validationSet = balance_by_multiple_attributes(remaining, ['age_label', 'gender_label', 'race_label'], 25)\n",
    "# ## remove\n",
    "# validationSet = validationSet.drop(['age', 'gender','race'], axis=1)\n",
    "\n",
    "# ## just double checking that there are no overlap between the two sets\n",
    "# # check the file name of the training and validation sets via if loop (using tqdm?)\n",
    "# training_files = set(trainingSet['file'])\n",
    "# validation_files = set(validationSet['file'])\n",
    "\n",
    "# print(training_files)\n",
    "# print(validation_files)\n",
    "\n",
    "# print(f\"overlap b/w training and validation sets: {overlap}\")\n",
    "# print(f\"size of overlap: {len(overlap)}\")\n",
    "\n",
    "\n",
    "# print(newSet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "63a0a94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              file    age  gender             race  age_label  gender_label  \\\n",
      "0     val/2890.jpg  30-39    Male           Indian          4             1   \n",
      "1     val/1835.jpg    3-9    Male            Black          3             1   \n",
      "2     val/8980.jpg    3-9    Male  Southeast Asian          3             1   \n",
      "3     val/8228.jpg  30-39    Male       East Asian          4             1   \n",
      "4     val/3689.jpg  30-39  Female           Indian          4             0   \n",
      "...            ...    ...     ...              ...        ...           ...   \n",
      "7703  val/6864.jpg  10-19  Female            Black          1             0   \n",
      "7704  val/9091.jpg  30-39  Female  Southeast Asian          4             0   \n",
      "7705  val/4253.jpg  40-49    Male   Middle Eastern          5             1   \n",
      "7706   val/737.jpg    3-9    Male            White          3             1   \n",
      "7707  val/5974.jpg    3-9    Male           Indian          3             1   \n",
      "\n",
      "      race_label  \n",
      "0              2  \n",
      "1              0  \n",
      "2              5  \n",
      "3              1  \n",
      "4              2  \n",
      "...          ...  \n",
      "7703           0  \n",
      "7704           5  \n",
      "7705           4  \n",
      "7706           6  \n",
      "7707           2  \n",
      "\n",
      "[7708 rows x 7 columns]\n",
      "age_label\n",
      "7    3\n",
      "1    2\n",
      "5    2\n",
      "3    1\n",
      "6    1\n",
      "2    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation set output\n",
    "# name = valSet\n",
    "print(valSet)\n",
    "## Age labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(name['age_label'].value_counts().index, name['age_label'].value_counts().values)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "## count how many are label 7 and 8\n",
    "print(name['age_label'].value_counts())\n",
    "# 3270 as a combination of 7 and 8 before combinations\n",
    "# \n",
    "\n",
    "## Gender labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(name['gender_label'].value_counts().index, name['gender_label'].value_counts().values)\n",
    "plt.title('Gender Distribution')\n",
    "plt.xlabel('Gender Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "## Race labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(name['race_label'].value_counts().index, name['race_label'].value_counts().values)\n",
    "plt.title('Race Distribution')\n",
    "plt.xlabel('Race Label')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddddefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## export the training and validation sets to csv files\n",
    "\n",
    "# # before randomizing\n",
    "# print(\"Before randomizing:\")\n",
    "# print(trainingSet.head())\n",
    "# print(validationSet.head())\n",
    "# print(\"================================================================\")\n",
    "\n",
    "# # randomize the training and validation sets\n",
    "# trainingSet = trainingSet.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# validationSet = validationSet.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # after randomizing\n",
    "# print(trainingSet.head())\n",
    "# print(validationSet.head())\n",
    "\n",
    "# # create a new direcotry called Datasets\n",
    "# if not os.path.exists('Datasets'):\n",
    "#     os.makedirs('Datasets')\n",
    "\n",
    "# trainingSet.to_csv('Datasets/trainingSet.csv', index=False)\n",
    "# validationSet.to_csv('Datasets/validationSet.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "e4f7b4d7809f3ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:23:11.553965Z",
     "start_time": "2025-04-22T19:23:11.524495Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female', 'Male']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Output of Encoding for age and race\n",
    "# tester111 = (list(zip(age_encoder.classes_, range(len(age_encoder.classes_)))))  ## output is in format of [(class, index), ...]\n",
    "tester111 = (list(zip(gender_encoder.classes_, range(len(gender_encoder.classes_)))))\n",
    "\n",
    "## need to change to [class, class, class, ...]\n",
    "for i in range(len(tester111)):\n",
    "    tester111[i] = tester111[i][0]\n",
    "print(tester111)\n",
    "    \n",
    "# print(list(zip(gender_encoder.classes_, range(len(gender_encoder.classes_)))))\n",
    "# print(list(zip(race_encoder.classes_, range(len(race_encoder.classes_)))))\n",
    "\n",
    "def getEncodeDecoded():\n",
    "    print((list(zip(age_encoder.classes_, range(len(age_encoder.classes_))))))\n",
    "    print(list(zip(gender_encoder.classes_, range(len(gender_encoder.classes_)))))\n",
    "    print(list(zip(race_encoder.classes_, range(len(race_encoder.classes_)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "304aa3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL   import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# ── transforms ──────────────────────────────────────────────\n",
    "IMG_SIZE = 224\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ── dataset ─────────────────────────────────────────────────\n",
    "class FairFaceMulti(Dataset):\n",
    "    def __init__(self, df, img_dir, train=True):\n",
    "        self.df       = df.reset_index(drop=True)\n",
    "        self.img_dir  = Path(img_dir)\n",
    "        self.tfm      = train_tfms if train else val_tfms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row   = self.df.iloc[idx]\n",
    "        img_p = self.img_dir / Path(row.file).name   # robust join\n",
    "        img   = Image.open(img_p).convert(\"RGB\")\n",
    "        age    = torch.tensor(row.age_label,    dtype=torch.long)\n",
    "        gender = torch.tensor(row.gender_label, dtype=torch.long)\n",
    "        race = torch.tensor(row.race_label, dtype=torch.long)\n",
    "\n",
    "        return self.tfm(img), {\"age\": age, \"gender\": gender, \"race\": race}\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"FairFaceMulti(n={len(self)}, dir={self.img_dir})\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d15ca26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class AgeGenderNet(nn.Module):\n",
    "    def __init__(self, n_age=9, n_gender=2, n_race=7, backbone=\"resnet18\"):\n",
    "        super().__init__()\n",
    "        self.backbone = getattr(models, backbone)(weights=\"IMAGENET1K_V1\")\n",
    "        dim = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()          # remove final FC\n",
    "\n",
    "        self.age_head    = nn.Linear(dim, n_age)      # 9 classes\n",
    "        self.gender_head = nn.Linear(dim, n_gender)   # 2 classes\n",
    "        self.race_head = nn.Linear(dim, n_race)   # 2 classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        return {\n",
    "            \"age\":    self.age_head(feat),\n",
    "            \"gender\": self.gender_head(feat),\n",
    "            \"race\": self.race_head(feat)\n",
    "\n",
    "        }\n",
    "\n",
    "model = AgeGenderNet().cuda()\n",
    "loss_age    = nn.CrossEntropyLoss()\n",
    "loss_gender = nn.CrossEntropyLoss()     # fairly balanced already\n",
    "loss_race = nn.CrossEntropyLoss()     # fairly balanced already\n",
    "\n",
    "\n",
    "def criterion(pred_dict, target_dict, λ_age=1.0, λ_gender=1.0, λ_race=1.0):\n",
    "    L_age    = loss_age(pred_dict[\"age\"],    target_dict[\"age\"])\n",
    "    L_gender = loss_gender(pred_dict[\"gender\"], target_dict[\"gender\"])\n",
    "    L_race = loss_race(pred_dict[\"race\"], target_dict[\"race\"])\n",
    "\n",
    "    \n",
    "    return λ_age*L_age + λ_gender*L_gender + λ_race*L_race , {\"age\": L_age.item(),\n",
    "                                            \"gender\": L_gender.item(), \"race\": L_race.item()}\n",
    "    \n",
    "    \n",
    "## optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nvidia-smi\n",
    "nvidia_smi = os.popen(\"nvidia-smi\").read()\n",
    "!nvidia-smi\n",
    "# check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0da76a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    epoch_loss, correct_age, correct_gender, correct_race, n = 0,0,0,0,0 # Initialize n=0\n",
    "    print(f\"Starting {'training' if train else 'validation'} epoch...\")\n",
    "    batch_num = 0\n",
    "    for imgs, targets in tqdm.tqdm(loader):\n",
    "        # print(f\"Processing batch {batch_num}\")\n",
    "        batch_num += 1\n",
    "        try:\n",
    "            imgs = imgs.cuda()\n",
    "            t_age    = targets[\"age\"].cuda()\n",
    "            t_gender = targets[\"gender\"].cuda()\n",
    "            t_race   = targets[\"race\"].cuda() # Get race target\n",
    "\n",
    "            with torch.set_grad_enabled(train):\n",
    "                preds = model(imgs)\n",
    "                loss, parts = criterion(preds, {\"age\":t_age, \"gender\":t_gender, \"race\": t_race}) # Include race in criterion if needed\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            _, pa = preds[\"age\"].max(1)\n",
    "            _, pg = preds[\"gender\"].max(1)\n",
    "            _, pr = preds[\"race\"].max(1) # Use pr for race prediction index\n",
    "\n",
    "            correct_age    += (pa==t_age).sum().item()\n",
    "            correct_gender += (pg==t_gender).sum().item()\n",
    "            correct_race   += (pr==t_race).sum().item() # Calculate correct race predictions\n",
    "\n",
    "            n += imgs.size(0)\n",
    "            epoch_loss += loss.item()*imgs.size(0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_num-1}: {e}\")\n",
    "            # Decide if you want to stop or continue\n",
    "            # raise # Re-raise the exception to stop execution\n",
    "            # continue # Skip this batch and continue\n",
    "\n",
    "    print(f\"Finished {'training' if train else 'validation'} epoch.\")\n",
    "    # Handle potential division by zero if n remains 0\n",
    "    if n == 0:\n",
    "        print(\"Warning: No items processed in the loader.\")\n",
    "        return (0, 0, 0, 0) # Return 4 zeros\n",
    "    # Return loss and all three accuracies\n",
    "    return (epoch_loss/n,\n",
    "            correct_age/n,\n",
    "            correct_gender/n,\n",
    "            correct_race/n) # Add race accuracy to the return tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992119b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## just recalling the variables\n",
    "trainingSet = trainingSet\n",
    "validationSet = validationSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f04f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 400\n",
      "Length of val_loader: 34\n",
      "Starting training epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 21/400 [00:07<02:23,  2.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     26\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 28\u001b[0m     tr_loss, tr_acc_age, tr_acc_gen, tr_acc_race \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     vl_loss, vl_acc_age, vl_acc_gen, vl_acc_race \u001b[38;5;241m=\u001b[39m run_epoch(val_loader,   train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[17], line 16\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(loader, train)\u001b[0m\n\u001b[0;32m     13\u001b[0m t_race   \u001b[38;5;241m=\u001b[39m targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;66;03m# Get race target\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(train):\n\u001b[1;32m---> 16\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     loss, parts \u001b[38;5;241m=\u001b[39m criterion(preds, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m:t_age, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m:t_gender, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m: t_race}) \u001b[38;5;66;03m# Include race in criterion if needed\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m, in \u001b[0;36mAgeGenderNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 17\u001b[0m     feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m:    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mage_head(feat),\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgender_head(feat),\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrace_head(feat)\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\resnet.py:97\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[1;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, time, datetime\n",
    "from statistics import mean\n",
    "\n",
    "## the actual training\n",
    "train_ds = FairFaceMulti(trainingSet,   \"FairFace/train\", train=True)\n",
    "val_ds   = FairFaceMulti(validationSet, \"FairFace/train\", train=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "# Check the length of the dataset\n",
    "print(f\"Length of train_loader: {len(train_loader)}\")\n",
    "print(f\"Length of val_loader: {len(val_loader)}\")\n",
    "\n",
    "## location to store models\n",
    "if not os.path.exists('checkpoints'):\n",
    "    os.makedirs('checkpoints')\n",
    "\n",
    "EPOCHS = 10\n",
    "# to keep track of time\n",
    "epoch_times = [] \n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    tr_loss, tr_acc_age, tr_acc_gen, tr_acc_race = run_epoch(train_loader, train=True)\n",
    "    vl_loss, vl_acc_age, vl_acc_gen, vl_acc_race = run_epoch(val_loader,   train=True)\n",
    "    scheduler.step()\n",
    "    # Initialize variables for ETA calculation\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate elapsed time and ETA\n",
    "    epoch_times.append(time.time() - t0)\n",
    "    avg_epoch   = mean(epoch_times)\n",
    "    remaining   = EPOCHS - (epoch + 1)\n",
    "    eta_seconds = avg_epoch * remaining\n",
    "    eta_str     = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "\n",
    "    # Format ETA as HH:MM:SS\n",
    "    eta_formatted = time.strftime(\"%H:%M:%S\", time.gmtime(eta))\n",
    "    \n",
    "    ## incramentally save the model after every 20 epochs\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        torch.save(model.state_dict(), f\"checkpoints/model_epoch_{epoch+1}.pth\")\n",
    "        print(f\"Model saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(\n",
    "        f\"{epoch:02d}  \"\n",
    "        f\"tr_loss={tr_loss:.3f}  vl_loss={vl_loss:.3f} |\\n\"\n",
    "        f\"TRAIN  age={tr_acc_age:.2%}  gen={tr_acc_gen:.2%}  race={tr_acc_race:.2%} |\\n\"\n",
    "        f\"VAL    age={vl_acc_age:.2%}  gen={vl_acc_gen:.2%}  race={vl_acc_race:.2%} |\\n\"\n",
    "        f\"ETA ~ {eta_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c14fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model after training\n",
    "\n",
    "ckpt_path = \"checkpoints/best_multitask.pth\"\n",
    "ckpt = {\n",
    "    \"epoch\"      : epoch,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer\"  : optimizer.state_dict(),   # optional\n",
    "    \"age_encoder\": age_encoder.classes_.tolist(),  # any extra objects you need\n",
    "}\n",
    "torch.save(ckpt, ckpt_path)\n",
    "print(\"✅  Saved checkpoint →\", ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # images need to be randomly selected\n",
    "# import random\n",
    "\n",
    "# # loading in the dataset and getting some metrics out of it\n",
    "# testSet = pd.read_csv('FairFace/fairface_label_val.csv')\n",
    "\n",
    "# # remove service_test column\n",
    "# testSet = testSet.drop(columns=['service_test'])\n",
    "# ## Combining the age bins of '60-69' and 'more than 70' into '60+' and relabeling the age bins\n",
    "# testSet['age'] = testSet['age'].replace({'60-69': '60+', 'more than 70': '60+'})\n",
    "# # rename Latino_Hispanic to Latino\n",
    "# testSet['race'] = testSet['race'].replace({'Latino_Hispanic': 'Latino'})\n",
    "\n",
    "# testSet = testSet.drop_duplicates(subset=['file'], keep='first')\n",
    "\n",
    "\n",
    "# # encoding categorical labels\n",
    "# age_bins = ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60+']\n",
    "\n",
    "# # new column 'age' with the bins from above\n",
    "# testSet = testSet[testSet['age'].isin(age_bins)]  # ensure only those bins are used\n",
    "\n",
    "# ## these will be used to check what the encoding and decoding looks like\n",
    "# age_encoder = LabelEncoder()\n",
    "# testSet['age_label'] = age_encoder.fit_transform(testSet['age'])\n",
    "\n",
    "# gender_encoder = LabelEncoder()\n",
    "# testSet['gender_label'] = gender_encoder.fit_transform(testSet['gender'])\n",
    "\n",
    "# race_encoder = LabelEncoder()\n",
    "# testSet['race_label'] = race_encoder.fit_transform(testSet['race'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041a74fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished copying files.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age_label</th>\n",
       "      <th>gender_label</th>\n",
       "      <th>race_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>val/1282.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>val/8288.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>val/9785.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>val/8661.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>val/10874.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>val/4092.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>val/1705.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Indian</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>val/491.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>val/2946.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>val/398.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>val/9083.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>val/2380.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>val/3805.jpg</td>\n",
       "      <td>60+</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>val/10057.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>val/4153.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Male</td>\n",
       "      <td>Indian</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>val/1465.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>val/5628.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>val/4816.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>val/9503.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>val/9997.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>val/4204.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>val/6177.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6948</th>\n",
       "      <td>val/7300.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>val/3631.jpg</td>\n",
       "      <td>60+</td>\n",
       "      <td>Male</td>\n",
       "      <td>Indian</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>val/4428.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file    age  gender             race  age_label  gender_label  \\\n",
       "161    val/1282.jpg  30-39    Male           Latino          4             1   \n",
       "819    val/8288.jpg  30-39  Female       East Asian          4             0   \n",
       "855    val/9785.jpg  10-19  Female            White          1             0   \n",
       "870    val/8661.jpg  20-29    Male            Black          2             1   \n",
       "1096  val/10874.jpg    3-9  Female  Southeast Asian          3             0   \n",
       "1393   val/4092.jpg  40-49    Male           Latino          5             1   \n",
       "1406   val/1705.jpg  30-39    Male           Indian          4             1   \n",
       "1765    val/491.jpg  10-19  Female            Black          1             0   \n",
       "2264   val/2946.jpg  40-49    Male  Southeast Asian          5             1   \n",
       "2329    val/398.jpg  30-39    Male            Black          4             1   \n",
       "2872   val/9083.jpg  20-29    Male            White          2             1   \n",
       "2959   val/2380.jpg  30-39    Male            Black          4             1   \n",
       "3016   val/3805.jpg    60+  Female           Latino          7             0   \n",
       "3115  val/10057.jpg  50-59  Female           Latino          6             0   \n",
       "3217   val/4153.jpg    3-9    Male           Indian          3             1   \n",
       "3328   val/1465.jpg  20-29    Male           Latino          2             1   \n",
       "3980   val/5628.jpg    3-9  Female           Latino          3             0   \n",
       "4729   val/4816.jpg  10-19    Male  Southeast Asian          1             1   \n",
       "5505   val/9503.jpg  20-29  Female       East Asian          2             0   \n",
       "5862   val/9997.jpg  30-39  Female            Black          4             0   \n",
       "5992   val/4204.jpg  40-49  Female           Indian          5             0   \n",
       "6070   val/6177.jpg  30-39    Male   Middle Eastern          4             1   \n",
       "6948   val/7300.jpg  20-29    Male           Indian          2             1   \n",
       "7405   val/3631.jpg    60+    Male           Indian          7             1   \n",
       "7649   val/4428.jpg  20-29  Female            White          2             0   \n",
       "\n",
       "      race_label  \n",
       "161            3  \n",
       "819            1  \n",
       "855            6  \n",
       "870            0  \n",
       "1096           5  \n",
       "1393           3  \n",
       "1406           2  \n",
       "1765           0  \n",
       "2264           5  \n",
       "2329           0  \n",
       "2872           6  \n",
       "2959           0  \n",
       "3016           3  \n",
       "3115           3  \n",
       "3217           2  \n",
       "3328           3  \n",
       "3980           3  \n",
       "4729           5  \n",
       "5505           1  \n",
       "5862           0  \n",
       "5992           2  \n",
       "6070           4  \n",
       "6948           2  \n",
       "7405           2  \n",
       "7649           6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "# --- Make sure valSet is defined correctly from your validation data ---\n",
    "# Example: valSet = validationSet # Assuming validationSet is your DataFrame\n",
    "\n",
    "## Need to take around 25-30 image from the val folder in FairFace and put them in a folder called test\n",
    "# define the two source base directory and the destination directory\n",
    "\n",
    "\n",
    "def createTestSet(TEST_SIZE):\n",
    "    df_source = valSet.copy()\n",
    "    source_base_dir = \"FairFace\" ## where it's coming from\n",
    "    test_dir = \"FairFace/test\"   ## where it'll go\n",
    "\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "        \n",
    "    ## check what files are in the directory and remove all\n",
    "    for filename in os.listdir(test_dir):\n",
    "        file_path = os.path.join(test_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                # print(f\"Removed {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {file_path}: {e}\")\n",
    "\n",
    "    # get a list of all the files (relative paths like 'val/xxxx.jpg') in the validation set\n",
    "    \n",
    "    testFiles = df_source['file'].tolist()\n",
    "    random_files = [] # initalize empty list first\n",
    "\n",
    "    # this randomly select 25 files\n",
    "    \n",
    "    if len(testFiles) >= 25:\n",
    "        random_files = random.sample(testFiles, TEST_SIZE)\n",
    "    else:\n",
    "        print(f\"Warning: Only {len(testFiles)} files available in validation set. Selecting all.\")\n",
    "        # random_files = testFiles\n",
    "        # print(testFiles)\n",
    "        # print(len(random_files))\n",
    "\n",
    "    # print(f\"Attempting to copy {len(random_files)} files to {test_dir}...\")\n",
    "    # print(len(random_files))\n",
    "\n",
    "    # Copy the files to the test directory\n",
    "    for file_relative_path in random_files:\n",
    "        # source path\n",
    "        src = os.path.join(source_base_dir, file_relative_path)\n",
    "        # file name\n",
    "        file_basename = os.path.basename(file_relative_path)\n",
    "        # dest pat\n",
    "        dst = os.path.join(test_dir, file_basename)\n",
    "        \n",
    "        # loop through the files and copy them to the test directory\n",
    "        try:\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy2(src, dst) # Use shutil.copy2 for better copying\n",
    "                # print(f\"Copied {src} to {dst}\")\n",
    "            else:\n",
    "                print(f\"Error: Source file {src} does not exist.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {src} to {dst}: {e}\")\n",
    "\n",
    "    print(\"Finished copying files.\")\n",
    "\n",
    "    ## Now need to create a new CSV file for all of the information regarding the files in the test directory\n",
    "    # gen idea is to go call the val csv file and drop all rows that do not have the file name in the test directory\n",
    "\n",
    "    files = os.listdir(test_dir)\n",
    "    # Get the file names without the dir path\n",
    "    files = [os.path.basename(file) for file in files]\n",
    "\n",
    "    # new of val labels\n",
    "    ## file column contains file names in the style of val/xxxx.jpg\n",
    "    # filter df2 to only include rows where the 'file' column matches any of the file names in the test directory\n",
    "    # Extract the basename from the 'file' column in df2\n",
    "    df2_basenames = df_source['file'].str.split('/').str[-1]\n",
    "\n",
    "    # Filter df2 where the basename is in the 'files' list\n",
    "    current_sef_labels_df = df_source[df2_basenames.isin(files)].copy() # Use .copy() to avoid some err\n",
    "    # testertester.drop(columns=['age_label', 'gender_label', 'race_label'], inplace=True)\n",
    "    # print(testertester)\n",
    "\n",
    "    ## save as csv in the file path\n",
    "    current_sef_labels_df.to_csv('FairFace/fairface_label_test.csv', index=False)\n",
    "    \n",
    "    return current_sef_labels_df\n",
    "createTestSet(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "ac908a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_41780\\1567078367.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r\"checkpoints\\model_epoch_200.pth\"))\n"
     ]
    }
   ],
   "source": [
    "## Testing the model\n",
    "## select the model\n",
    "model = AgeGenderNet()\n",
    "model.load_state_dict(torch.load(r\"checkpoints\\model_epoch_200.pth\"))\n",
    "model.eval()                      \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "@torch.inference_mode()                  # no gradients, saves memory\n",
    "def predict_img(img_path: str):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x   = val_tfms(img).unsqueeze(0).to(device)     # shape (1,3,224,224)\n",
    "\n",
    "    out = model(x)                       # tuple OR dict, depending on your net\n",
    "    age_id    = out[\"age\"].argmax(1).item()\n",
    "    gender_id = out[\"gender\"].argmax(1).item()\n",
    "    race_id   = out[\"race\"].argmax(1).item()\n",
    "    \n",
    "    # print(\"ID INFO\")\n",
    "    # print(f\"Age ID: {age_id}, Gender ID: {gender_id}, Race ID: {race_id}\")\n",
    "\n",
    "    # class-name look-up tables (same order you used to encode)\n",
    "    age_classes = (list(zip(age_encoder.classes_, range(len(age_encoder.classes_)))))  ## output is in format of [(class, index), ...]\n",
    "    gender_map = (list(zip(gender_encoder.classes_, range(len(gender_encoder.classes_)))))\n",
    "    race_classes = (list(zip(race_encoder.classes_, range(len(race_encoder.classes_)))))\n",
    "    \n",
    "    ## need to change to [class, class, class, ...]\n",
    "    for i in range(len(age_classes)):\n",
    "        age_classes[i] = age_classes[i][0]\n",
    "    # print(age_classes)\n",
    "    \n",
    "    ## repeat for the other two\n",
    "    for i in range(len(gender_map)):\n",
    "        gender_map[i] = gender_map[i][0]\n",
    "    # print(gender_map)\n",
    "    \n",
    "    for i in range(len(race_classes)):\n",
    "        race_classes[i] = race_classes[i][0]\n",
    "    # print(race_classes)\n",
    "            \n",
    "    return age_classes[age_id], gender_map[gender_id], race_classes[race_id]\n",
    "\n",
    "\n",
    "# img_dir = r\"FairFace/test/2548.jpg\"\n",
    "# result = predict_img(img_dir)   # any face image\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "67b27d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished copying files.\n",
      "Age accuracy: 0.24\n",
      "Gender Accuracy: 0.6\n",
      "Race Accuracy: 0.12\n"
     ]
    }
   ],
   "source": [
    "# load in testing csv set\n",
    "\n",
    "\n",
    "\n",
    "## test with batches\n",
    "def model_test_batch():\n",
    "    valFilePath = \"FairFace/fairface_label_test.csv\"\n",
    "    valSet = pd.read_csv(valFilePath)\n",
    "    test_path = r\"FairFace\\test\"\n",
    "\n",
    "    # get all files in the test directory, in format: FairFace/test/xxxx.jpg\n",
    "    test_files = os.listdir(test_path)\n",
    "    test_files = [os.path.join(test_path, file) for file in test_files]\n",
    "    \n",
    "    # extract values of age_range, gender, and race from the valSet and save it to a list for accuracy comparison later\n",
    "    # this should only already contain the files that are in the test directory\n",
    "    # age list should be: [3-9, 10-19, 20-29, 30-39, 40-49, 50-59, 60+, ...] for each image\n",
    "    \n",
    "    true_age_list = valSet['age'].tolist()\n",
    "    true_gender_list = valSet['gender'].tolist()\n",
    "    true_race_list = valSet['race'].tolist()\n",
    "    \n",
    "    # print(true_age_list)\n",
    "    \n",
    "    # empty lists to store the predictions\n",
    "    pred_age_list = []\n",
    "    pred_gender_list = []\n",
    "    pred_race_list = []\n",
    "    \n",
    "    # loop through the test files and get the predictions\n",
    "    for file in test_files:\n",
    "        pred_age, pred_gender, pred_race = predict_img(file)\n",
    "        pred_age_list.append(pred_age), pred_gender_list.append(pred_gender), pred_race_list.append(pred_race)\n",
    "    # print(pred_age_list)\n",
    "    # print accuracies\n",
    "    print(f\"Age accuracy: {accuracy_score(true_age_list, pred_age_list)}\\n\"\n",
    "          f\"Gender Accuracy: {accuracy_score(true_gender_list, pred_gender_list)}\\n\"\n",
    "          f\"Race Accuracy: {accuracy_score(true_race_list, pred_race_list)}\")\n",
    "    \n",
    "createTestSet(25)\n",
    "model_test_batch()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "0e32c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 10 images:\n",
      "Finished copying files.\n",
      "Age accuracy: 0.0\n",
      "Gender Accuracy: 0.4\n",
      "Race Accuracy: 0.1\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing with 25 images:\n",
      "Finished copying files.\n",
      "Age accuracy: 0.28\n",
      "Gender Accuracy: 0.4\n",
      "Race Accuracy: 0.16\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing with 50 images:\n",
      "Finished copying files.\n",
      "Age accuracy: 0.14\n",
      "Gender Accuracy: 0.52\n",
      "Race Accuracy: 0.08\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing with 100 images:\n",
      "Finished copying files.\n",
      "Age accuracy: 0.21\n",
      "Gender Accuracy: 0.54\n",
      "Race Accuracy: 0.21\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing with 500 images:\n",
      "Finished copying files.\n",
      "Age accuracy: 0.138\n",
      "Gender Accuracy: 0.476\n",
      "Race Accuracy: 0.156\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing with 1000 images:\n",
      "Finished copying files.\n",
      "Age accuracy: 0.146\n",
      "Gender Accuracy: 0.541\n",
      "Race Accuracy: 0.152\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing with 2000 images:\n",
      "Finished copying files.\n",
      "Age accuracy: 0.1395\n",
      "Gender Accuracy: 0.503\n",
      "Race Accuracy: 0.124\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def testDiffTestSizes():\n",
    "    # Define the test sizes you want to try\n",
    "    test_sizes = [10, 25, 50, 100, 500, 1000, 2000]\n",
    "\n",
    "    # Loop through each test size\n",
    "    for size in test_sizes:\n",
    "        print(f\"Testing with {size} images:\")\n",
    "        createTestSet(size)\n",
    "        model_test_batch()\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator for readability\n",
    "\n",
    "testDiffTestSizes()\n",
    "# print(testFiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
